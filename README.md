To add on this, **the Estonia paper** was rejected again from **Track-3 (as submission 46)** although enermous improvements were added that do not exist in any SoK of the Estonian i-voting IVXV; especially when you compare with other accepted paper (https://link.springer.com/chapter/10.1007/978-3-032-05036-6_13)


Also **the last paragraph of my future work since 2024** 
_"it could be an interesting research to tackle the broader question of to what limit can the information provided by general purpose activity logs of digital identities (in any country that uses digital identities in online voting) help vote buyers/coercers in catching voters who tries to deceive them, and whether a blockchain based e-government is an advantage or disadvantage in that direction. We have shown in section 6.4 the information myID [47] and similar services can provide; to what limit could adversaries use them to defeat, for example, the CK (Complete Knowledge) authenticity metric [65/footnote 21] whether for vote buying/coercion or any other malicious activity. "
_
was the idea behind another paper      (https://link.springer.com/chapter/10.1007/978-3-032-05036-6_12 )
who did not cite me claiming they did not and will not read or cite my paper until it is accepted by a weel ranked peer-reviewed conference/journal

{ I also cited in a footnote the 2023 poster the paper cites as my footnote 27:- **https://x.com/trtram/status/1763936733027049606) demonstrates how a sophisticated user can do that."**)

this is a temporary folder to hold the unreasonable  reviewers reports as html files

( **6 is the Estonian** i-voting paper in **Track-1** ,  **13 is the court verifiability** e-voting paper)


Html files are hard to view here, download first

Let me acknowledge that I have doubts that there was some kind of hacking/penetration such that those are fake reviews (but this necessiates that the sending emails were also penetrated, not just that I was deceived to upload into a malicious fake site) 


when sending to Track-3 now, I kept generating AI review reports from grok (X formerly Twitter), Gemini (Google), Capilot (Microdoft); then prepare a revised version accordingly 
The last Gemini report is uploaded here

The last Copilot report can be found in (https://copilot.microsoft.com/chats/m8NQsuYgD5LqXCvyVmu6N), 
I may add a table as it suggests in the extended version only, but i'm worried why it missed some details at the beginning (like explicit statements in Fig.2 caption about red & green colors)
Ps.

All generated reports recommended acceptance with minor revisions, which I keep doing
